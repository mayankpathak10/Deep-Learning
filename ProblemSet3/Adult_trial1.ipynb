{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd.variable import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "batch_size = 3\n",
    "num_epochs = 10\n",
    "num_classes = 2\n",
    "input_size = 67\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.load('Adult/data.npy').astype('float32')\n",
    "input_labels = np.load('Adult/labels.npy').astype('float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45222,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape\n",
    "input_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(input_data,input_labels,\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a training set\n",
    "tensor_x = torch.from_numpy(train_data).float()\n",
    "tensor_y = torch.from_numpy(train_labels).long()\n",
    "train_set = Data.TensorDataset(tensor_x,tensor_y)\n",
    "\n",
    "#Create a test set\n",
    "tensor_x = torch.from_numpy(test_data).float()\n",
    "tensor_y = torch.from_numpy(test_labels).long()\n",
    "test_set = Data.TensorDataset(tensor_x,tensor_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle= True)\n",
    "\n",
    "test_loader = Data.DataLoader(dataset = test_set, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(input_size, 55),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(55, 35),\n",
    "            nn.ReLU())\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(35,num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    for i, (data, labels) in enumerate(test_loader):\n",
    "\n",
    "        # Predict classes using images from the test set\n",
    "        data = Variable(data)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(data)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        \n",
    "#         prediction = prediction.data\n",
    "#         prediction =\n",
    "        test_acc = (i*test_acc +\n",
    "                    torch.mean(prediction.eq(labels.data).float()))/(i+1)\n",
    "\n",
    "    # Compute the average acc and loss over all 10000 test images\n",
    "#     test_acc = test_acc / 10000\n",
    "\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a learning rate adjustment function that divides the learning rate by 10 every 30 epochs\n",
    "def adjust_learning_rate(epoch):\n",
    "    lr = learning_rate\n",
    "\n",
    "    if epoch > 100:\n",
    "        lr = lr / 1000000\n",
    "    elif epoch > 50:\n",
    "        lr = lr / 100000\n",
    "    elif epoch > 20:\n",
    "        lr = lr / 10000\n",
    "    elif epoch > 10:\n",
    "        lr = lr / 1000\n",
    "    elif epoch > 5:\n",
    "        lr = lr / 100\n",
    "    elif epoch > 2:\n",
    "        lr = lr / 10\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay= weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('-'*10)\n",
    "        print(\"Epoch: {}/{} \\n\".format(epoch+1,num_epochs))\n",
    "    #     losses = []\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for i ,(x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs =  Variable(x)\n",
    "            output = model(inputs)\n",
    "            targets = Variable(y.squeeze(-1))\n",
    "            targets = targets.type(torch.LongTensor)\n",
    "\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            y = Variable(y)\n",
    "            train_loss = (train_loss*i + loss.data[0])/(i+1)\n",
    "            _, prediction = torch.max(output.data, 1)\n",
    "\n",
    "            train_acc = (i*train_acc +\n",
    "                 torch.mean(prediction.eq(y.data).float()))/(i+1)\n",
    "    #         break\n",
    "            adjust_learning_rate(epoch)\n",
    "#     break\n",
    "        # Evaluate on the test set\n",
    "        test_acc = test()\n",
    "\n",
    "        # Save the model if the test acc is greater than our current best\n",
    "        if test_acc > best_acc:\n",
    "#             save_models(epoch)\n",
    "            best_acc = test_acc\n",
    "            \n",
    "\n",
    "        # Print the metrics\n",
    "        print(\"Epoch {}, Train Accuracy: {} , TrainLoss: {:.4f} , Test Accuracy: {}\".format(epoch+1, train_acc, train_loss,test_acc))\n",
    "    print('\\nbest_acc = ', best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training Network\n",
      "----------\n",
      "Epoch: 1/10 \n",
      "\n",
      "Epoch 1, Train Accuracy: 0.8203278326008202 , TrainLoss: 0.3776 , Test Accuracy: 0.8309563294637912\n",
      "----------\n",
      "Epoch: 2/10 \n",
      "\n",
      "Epoch 2, Train Accuracy: 0.8354479365342585 , TrainLoss: 0.3499 , Test Accuracy: 0.8357103372028735\n",
      "----------\n",
      "Epoch: 3/10 \n",
      "\n",
      "Epoch 3, Train Accuracy: 0.8382674074688304 , TrainLoss: 0.3462 , Test Accuracy: 0.8323935876174674\n",
      "----------\n",
      "Epoch: 4/10 \n",
      "\n",
      "Epoch 4, Train Accuracy: 0.8459518478591275 , TrainLoss: 0.3291 , Test Accuracy: 0.8425649530127115\n",
      "----------\n",
      "Epoch: 5/10 \n",
      "\n",
      "Epoch 5, Train Accuracy: 0.8464217596815601 , TrainLoss: 0.3275 , Test Accuracy: 0.8452183526810376\n",
      "----------\n",
      "Epoch: 6/10 \n",
      "\n",
      "Epoch 6, Train Accuracy: 0.8469193133758935 , TrainLoss: 0.3265 , Test Accuracy: 0.8449972360420102\n",
      "----------\n",
      "Epoch: 7/10 \n",
      "\n",
      "Epoch 7, Train Accuracy: 0.8485225419465335 , TrainLoss: 0.3244 , Test Accuracy: 0.8447761194029831\n",
      "----------\n",
      "Epoch: 8/10 \n",
      "\n",
      "Epoch 8, Train Accuracy: 0.8484119744589046 , TrainLoss: 0.3241 , Test Accuracy: 0.8431177446102793\n",
      "----------\n",
      "Epoch: 9/10 \n",
      "\n",
      "Epoch 9, Train Accuracy: 0.8486054675622561 , TrainLoss: 0.3239 , Test Accuracy: 0.8456605859590914\n",
      "----------\n",
      "Epoch: 10/10 \n",
      "\n",
      "Epoch 10, Train Accuracy: 0.8482737650993671 , TrainLoss: 0.3238 , Test Accuracy: 0.8443338861249288\n",
      "\n",
      "best_acc =  0.8456605859590914\n",
      "\n",
      "\n",
      "Finished !!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Started Training Network\")\n",
    "    train(num_epochs)\n",
    "    print(\"\\n\\nFinished !!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
